{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "61a9fcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save report? no\n"
     ]
    }
   ],
   "source": [
    "import os, hashlib, datetime, time, json, numpy\n",
    "from pathlib import Path\n",
    "\n",
    "class FilePro:\n",
    "\n",
    "    def get_info(self):\n",
    "        \n",
    "        resultList = []     # list of dictionaries in which all dictionaries have properties of files which are..\n",
    "                            # ..from the folder project_1\n",
    "        \n",
    "        def calHashValue(filePath):\n",
    "            hashobj = hashlib.sha1()\n",
    "            file = open(filePath,'rb')\n",
    "            data = 0\n",
    "            while data!=b'':\n",
    "                data = file.read(1024)\n",
    "                hashobj.update(data)\n",
    "            return hashobj.hexdigest()\n",
    "\n",
    "        # accessing all files and folders through os.walk() function\n",
    "        # root, dirs, files variables will have the root path, directories and file names respectively\n",
    "        # created a dictionary called tempDict, this will store all the required properties of each file, with keys..\n",
    "        # ..as the file property name and values as the corrsponding file property value\n",
    "        # and then appending each file's tempDict to \"resultList\"\n",
    "        \n",
    "        for (root,dirs,files) in os.walk(\".\", topdown=True):         \n",
    "            for name in files:\n",
    "                tempDict = {}\n",
    "                filePath = os.path.join(root, name)\n",
    "                if os.path.splitext(filePath)[1]!= \".ipynb\" and os.path.splitext(filePath)[1]!= \"\":\n",
    "                    tempDict[\"filePath\"] = filePath\n",
    "                    tempDict[\"fileName\"] = Path(filePath).stem\n",
    "                    tempDict[\"fileExtension\"] = os.path.splitext(filePath)[1]\n",
    "                    tempDict[\"fileSize\"] = os.path.getsize(filePath)\n",
    "                    tempDict[\"fileLastModified\"] = str(datetime.date.fromtimestamp(os.path.getctime(filePath)))\n",
    "                    tempDict[\"fileHashValue\"] = calHashValue(filePath)\n",
    "                    resultList.append(tempDict)\n",
    "        \n",
    "        # writing \"resultList\" list to \"file_info\" file in json format\n",
    "        \n",
    "        with open(\"file_info\", \"w\") as fi:\n",
    "            json.dump(resultList, fi)\n",
    "\n",
    "    def __init__(self, currentWorkingDir):\n",
    "        self.currentWorkingDir = currentWorkingDir\n",
    "        filePath = currentWorkingDir+\"/file_info.csv\"\n",
    "        if not os.path.isfile(filePath):\n",
    "            self.get_info()\n",
    "        elif str(datetime.date.fromtimestamp(os.path.getctime(filePath)))<=str(datetime.date.fromtimestamp(time.time())):\n",
    "            self.get_info()\n",
    "            \n",
    "    def generate_report(self, currentWorkingDir):\n",
    "        \n",
    "        fileTypes = []               # sotres all the distinct file types\n",
    "        fileSizes = []               # stores all files file size, this is useful for calculating mean and median of..\n",
    "                                     # ..all files\n",
    "        meanByFileTypes = {}         # stores mean of each file type\n",
    "        medianByFileTypes = {}       # stores median of each file type\n",
    "        folderPaths = []             # stores paths of all folders, this is useful for building the..\n",
    "                                     # ..\"folderPathsAndFileCount\" dictionary\n",
    "        folderPathsAndFileCount = {} # stores number of files in each folder, with keys storing folder's path and..\n",
    "                                     # ..values storing corrresponding number of files\n",
    "        folderNames = []             # stores names of folders, this is useful for retrieving the folder name with..\n",
    "                                     # ..highest number of files and biggest size\n",
    "        \n",
    "        \n",
    "        self.currentWorkingDir = currentWorkingDir\n",
    "        filePath = currentWorkingDir+\"/file_info.csv\"\n",
    "        if not os.path.isfile(filePath):\n",
    "            self.get_info()\n",
    "        elif str(datetime.date.fromtimestamp(os.path.getctime(filePath)))<=str(datetime.date.fromtimestamp(time.time())):\n",
    "            self.get_info()\n",
    "   \n",
    "        fileInfo = open(\"file_info\",\"r\")   # opening the file in read mode\n",
    "        data = []                          # stores the data in \"file_info\" file\n",
    "        data = json.load(fileInfo)         # using json.load() function to retrieve the data in \"file_info\" file\n",
    "        for i in data:\n",
    "            \n",
    "            # here we are adding the file type to \"fileTypes\" list if a specific file type is not present in the list\n",
    "            \n",
    "            if i[\"fileExtension\"] not in fileTypes:          \n",
    "                fileTypes.append(i[\"fileExtension\"])\n",
    "            \n",
    "            # appending file sizes to \"fileSizes\" list, we can use this list to calcu;ate mean and median of all files\n",
    "            \n",
    "            fileSizes.append(i[\"fileSize\"])                  \n",
    "            \n",
    "            # here we are checking if a specific file type (as keys) is present in \"meanByFileTypes\" and \"medianByFileTypes\"..\n",
    "            # ..if it is not present we are adding that specific file type as key and an empty list as its..\n",
    "            # ..corresponding value which stores file sizes of the corresponding file type\n",
    "            # file sizes of same type will be appended to their respective lists \n",
    "            \n",
    "            if i[\"fileExtension\"] not in meanByFileTypes.keys():\n",
    "                meanByFileTypes[i[\"fileExtension\"]] = []\n",
    "                meanByFileTypes[i[\"fileExtension\"]].append(i[\"fileSize\"])\n",
    "                medianByFileTypes[i[\"fileExtension\"]] = []\n",
    "                medianByFileTypes[i[\"fileExtension\"]].append(i[\"fileSize\"])\n",
    "            else:\n",
    "                meanByFileTypes[i[\"fileExtension\"]].append(i[\"fileSize\"])\n",
    "                medianByFileTypes[i[\"fileExtension\"]].append(i[\"fileSize\"])\n",
    "                \n",
    "        # calculating mean and median of specific file types by accessing the list values in \"meanByFileTypes\" and..\n",
    "        #..\"medianByFileTypes\"\n",
    "                \n",
    "        for k in meanByFileTypes.keys():\n",
    "            meanByFileTypes[k] = numpy.mean(meanByFileTypes[k])\n",
    "            medianByFileTypes[k] = numpy.median(medianByFileTypes[k])\n",
    "        \n",
    "        for (root,dirs,files) in os.walk(\".\", topdown=True):            \n",
    "            for i in range(len(dirs)):\n",
    "                root = root.replace(\".\",\"\")                   # getting rid of \".\" for proper file path creation\n",
    "                folderPaths.append(os.path.join(root, dirs[i]))\n",
    "                folderNames.append(dirs[i])\n",
    "                \n",
    "        folderPaths[1] = \"/\"+folderPaths[1]\n",
    "        for keys in folderPaths:\n",
    "            folderPathsAndFileCount[keys] = 0\n",
    "        fileCount = [0]                                   # stores count of files of each folder, this is useful for..\n",
    "                                                          # ..calculating folder with highest number of files\n",
    "        \n",
    "        maxFolderSize = [0]                               # stores file size of each folder, this is useful for..\n",
    "                                                          # ..calculating folder with biggest size\n",
    "        \n",
    "        \n",
    "        # here are we calculating size of each folder and appending it to \"maxFodlerSize\" and also calculating count..\n",
    "        # ..of files and appending it to \"fileCount\"\n",
    "        \n",
    "        \n",
    "        for i in range(1, len(folderPaths)):              # here we are ignoring the value in base index as it..\n",
    "                                                          #..belongs to the current notebook\n",
    "            count = 0\n",
    "            size = 0\n",
    "            dirIter = os.scandir(currentWorkingDir+folderPaths[i])\n",
    "            for direc in dirIter:\n",
    "                if direc.is_file():\n",
    "                    count+=1\n",
    "                    size += os.path.getsize(direc)\n",
    "            maxFolderSize.append(size)\n",
    "            folderPathsAndFileCount[dirIter] = count\n",
    "            fileCount.append(count)\n",
    "        maxCountIndex = fileCount.index(max(fileCount))         # finding the index which has highest number of files\n",
    "        maxSizeIndex = maxFolderSize.index(max(maxFolderSize))  # finding the index which has biggest size\n",
    "        \n",
    "        # with the above two indices we can get the required folder names from \"folderNames\" list\n",
    "        \n",
    "        # finally, adding all the data that was collected in this function to the dictionary \"filesData\"\n",
    "        \n",
    "        filesData = {}\n",
    "        filesData[\"File Types\"] = fileTypes\n",
    "        filesData[\"Mean by file type\"] = meanByFileTypes\n",
    "        filesData[\"Median by file type\"] = medianByFileTypes\n",
    "        filesData[\"Mean of all file types\"] = numpy.mean(fileSizes)\n",
    "        filesData[\"Median of all file types\"] = numpy.median(fileSizes)\n",
    "        filesData[\"Folder with highest number of files\"] = folderNames[maxCountIndex]\n",
    "        filesData[\"Folder with biggest size\"] = folderNames[maxSizeIndex]\n",
    "        ask = str(input(\"Save report? \"))\n",
    "        if ask == \"yes\":\n",
    "            with open(\"generatedReport\", \"w\") as fi:\n",
    "                json.dump(filesData, fi)\n",
    "            print(\"Report saved with name generatedReport\")\n",
    "\n",
    "currentWorkingDir = os.getcwd()                         # retrieving the current working directory\n",
    "fileObj = FilePro(currentWorkingDir)                    # creating the FilePro object which will trigger __intit__\n",
    "fileObj.generate_report(currentWorkingDir)              # function call to generate the report\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f62634d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
